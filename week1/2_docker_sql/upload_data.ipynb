{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13862d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "545281ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.2'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "246fe5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('yellow_tripdata_2019-01.csv', nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0850ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8e219be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6176b949",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95228476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE yellow_taxi_data (\n",
      "\t\"VendorID\" BIGINT, \n",
      "\ttpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\ttpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tpassenger_count BIGINT, \n",
      "\ttrip_distance FLOAT(53), \n",
      "\t\"RatecodeID\" BIGINT, \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpayment_type BIGINT, \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tcongestion_surcharge FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(df, name='yellow_taxi_data', con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60c267cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iter = pd.read_csv('yellow_tripdata_2019-01.csv',iterator=True, chunksize=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed7c9674",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=next(df_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48bd9ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6aff625b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [VendorID, tpep_pickup_datetime, tpep_dropoff_datetime, passenger_count, trip_distance, RatecodeID, store_and_fwd_flag, PULocationID, DOLocationID, payment_type, fare_amount, extra, mta_tax, tip_amount, tolls_amount, improvement_surcharge, total_amount, congestion_surcharge]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(n=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e376a695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_sql(name='yellow_taxi_data', con=engine,if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e92f03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 356 ms, sys: 24.9 ms, total: 381 ms\n",
      "Wall time: 905 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time df.to_sql(name='yellow_taxi_data',con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed9d4324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ddf323a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunk..., took 1.119 second\n",
      "inserted another chunk..., took 0.777 second\n",
      "inserted another chunk..., took 0.710 second\n",
      "inserted another chunk..., took 0.695 second\n",
      "inserted another chunk..., took 0.719 second\n",
      "inserted another chunk..., took 0.902 second\n",
      "inserted another chunk..., took 0.710 second\n",
      "inserted another chunk..., took 0.726 second\n",
      "inserted another chunk..., took 0.698 second\n",
      "inserted another chunk..., took 0.709 second\n",
      "inserted another chunk..., took 0.698 second\n",
      "inserted another chunk..., took 0.717 second\n",
      "inserted another chunk..., took 0.781 second\n",
      "inserted another chunk..., took 1.074 second\n",
      "inserted another chunk..., took 0.834 second\n",
      "inserted another chunk..., took 0.796 second\n",
      "inserted another chunk..., took 0.749 second\n",
      "inserted another chunk..., took 0.729 second\n",
      "inserted another chunk..., took 0.845 second\n",
      "inserted another chunk..., took 0.735 second\n",
      "inserted another chunk..., took 0.737 second\n",
      "inserted another chunk..., took 0.938 second\n",
      "inserted another chunk..., took 0.716 second\n",
      "inserted another chunk..., took 0.727 second\n",
      "inserted another chunk..., took 0.775 second\n",
      "inserted another chunk..., took 0.725 second\n",
      "inserted another chunk..., took 0.721 second\n",
      "inserted another chunk..., took 0.763 second\n",
      "inserted another chunk..., took 0.728 second\n",
      "inserted another chunk..., took 0.924 second\n",
      "inserted another chunk..., took 0.724 second\n",
      "inserted another chunk..., took 0.741 second\n",
      "inserted another chunk..., took 0.721 second\n",
      "inserted another chunk..., took 0.730 second\n",
      "inserted another chunk..., took 0.723 second\n",
      "inserted another chunk..., took 0.711 second\n",
      "inserted another chunk..., took 0.711 second\n",
      "inserted another chunk..., took 0.716 second\n",
      "inserted another chunk..., took 0.932 second\n",
      "inserted another chunk..., took 0.720 second\n",
      "inserted another chunk..., took 0.812 second\n",
      "inserted another chunk..., took 0.728 second\n",
      "inserted another chunk..., took 0.726 second\n",
      "inserted another chunk..., took 0.722 second\n",
      "inserted another chunk..., took 0.716 second\n",
      "inserted another chunk..., took 0.730 second\n",
      "inserted another chunk..., took 0.743 second\n",
      "inserted another chunk..., took 0.935 second\n",
      "inserted another chunk..., took 0.718 second\n",
      "inserted another chunk..., took 0.725 second\n",
      "inserted another chunk..., took 0.729 second\n",
      "inserted another chunk..., took 0.718 second\n",
      "inserted another chunk..., took 0.728 second\n",
      "inserted another chunk..., took 0.750 second\n",
      "inserted another chunk..., took 0.729 second\n",
      "inserted another chunk..., took 0.748 second\n",
      "inserted another chunk..., took 0.911 second\n",
      "inserted another chunk..., took 0.728 second\n",
      "inserted another chunk..., took 0.714 second\n",
      "inserted another chunk..., took 0.764 second\n",
      "inserted another chunk..., took 0.738 second\n",
      "inserted another chunk..., took 0.690 second\n",
      "inserted another chunk..., took 0.717 second\n",
      "inserted another chunk..., took 0.719 second\n",
      "inserted another chunk..., took 0.705 second\n",
      "inserted another chunk..., took 0.721 second\n",
      "inserted another chunk..., took 0.903 second\n",
      "inserted another chunk..., took 0.768 second\n",
      "inserted another chunk..., took 0.739 second\n",
      "inserted another chunk..., took 0.753 second\n",
      "inserted another chunk..., took 0.754 second\n",
      "inserted another chunk..., took 0.724 second\n",
      "inserted another chunk..., took 0.715 second\n",
      "inserted another chunk..., took 0.750 second\n",
      "inserted another chunk..., took 0.930 second\n",
      "inserted another chunk..., took 0.717 second\n",
      "inserted another chunk..., took 0.771 second\n",
      "inserted another chunk..., took 0.713 second\n",
      "inserted another chunk..., took 0.736 second\n",
      "inserted another chunk..., took 0.702 second\n",
      "inserted another chunk..., took 0.763 second\n",
      "inserted another chunk..., took 0.721 second\n",
      "inserted another chunk..., took 0.726 second\n",
      "inserted another chunk..., took 0.983 second\n",
      "inserted another chunk..., took 0.851 second\n",
      "inserted another chunk..., took 0.721 second\n",
      "inserted another chunk..., took 0.785 second\n",
      "inserted another chunk..., took 0.732 second\n",
      "inserted another chunk..., took 0.788 second\n",
      "inserted another chunk..., took 0.771 second\n",
      "inserted another chunk..., took 0.742 second\n",
      "inserted another chunk..., took 0.733 second\n",
      "inserted another chunk..., took 0.924 second\n",
      "inserted another chunk..., took 0.824 second\n",
      "inserted another chunk..., took 0.727 second\n",
      "inserted another chunk..., took 0.741 second\n",
      "inserted another chunk..., took 0.966 second\n",
      "inserted another chunk..., took 0.825 second\n",
      "inserted another chunk..., took 0.752 second\n",
      "inserted another chunk..., took 0.790 second\n",
      "inserted another chunk..., took 0.748 second\n",
      "inserted another chunk..., took 0.984 second\n",
      "inserted another chunk..., took 0.741 second\n",
      "inserted another chunk..., took 0.738 second\n",
      "inserted another chunk..., took 0.713 second\n",
      "inserted another chunk..., took 0.705 second\n",
      "inserted another chunk..., took 0.773 second\n",
      "inserted another chunk..., took 0.738 second\n",
      "inserted another chunk..., took 0.735 second\n",
      "inserted another chunk..., took 0.721 second\n",
      "inserted another chunk..., took 1.081 second\n",
      "inserted another chunk..., took 0.712 second\n",
      "inserted another chunk..., took 0.716 second\n",
      "inserted another chunk..., took 0.709 second\n",
      "inserted another chunk..., took 0.737 second\n",
      "inserted another chunk..., took 0.700 second\n",
      "inserted another chunk..., took 0.737 second\n",
      "inserted another chunk..., took 0.713 second\n",
      "inserted another chunk..., took 0.725 second\n",
      "inserted another chunk..., took 0.706 second\n",
      "inserted another chunk..., took 0.876 second\n",
      "inserted another chunk..., took 0.722 second\n",
      "inserted another chunk..., took 0.904 second\n",
      "inserted another chunk..., took 0.704 second\n",
      "inserted another chunk..., took 0.713 second\n",
      "inserted another chunk..., took 0.766 second\n",
      "inserted another chunk..., took 1.626 second\n",
      "inserted another chunk..., took 1.732 second\n",
      "inserted another chunk..., took 2.130 second\n",
      "inserted another chunk..., took 1.821 second\n",
      "inserted another chunk..., took 2.040 second\n",
      "inserted another chunk..., took 1.886 second\n",
      "inserted another chunk..., took 1.030 second\n",
      "inserted another chunk..., took 0.930 second\n",
      "inserted another chunk..., took 1.052 second\n",
      "inserted another chunk..., took 1.021 second\n",
      "inserted another chunk..., took 1.211 second\n",
      "inserted another chunk..., took 0.805 second\n",
      "inserted another chunk..., took 0.949 second\n",
      "inserted another chunk..., took 0.700 second\n",
      "inserted another chunk..., took 0.702 second\n",
      "inserted another chunk..., took 0.698 second\n",
      "inserted another chunk..., took 0.743 second\n",
      "inserted another chunk..., took 0.728 second\n",
      "inserted another chunk..., took 0.712 second\n",
      "inserted another chunk..., took 0.697 second\n",
      "inserted another chunk..., took 0.706 second\n",
      "inserted another chunk..., took 1.007 second\n",
      "inserted another chunk..., took 0.698 second\n",
      "inserted another chunk..., took 0.697 second\n",
      "inserted another chunk..., took 0.710 second\n",
      "inserted another chunk..., took 0.680 second\n",
      "inserted another chunk..., took 0.683 second\n",
      "inserted another chunk..., took 0.710 second\n",
      "inserted another chunk..., took 0.750 second\n",
      "inserted another chunk..., took 0.819 second\n",
      "inserted another chunk..., took 0.740 second\n",
      "inserted another chunk..., took 0.708 second\n",
      "inserted another chunk..., took 0.748 second\n",
      "inserted another chunk..., took 0.718 second\n",
      "inserted another chunk..., took 0.697 second\n",
      "inserted another chunk..., took 0.760 second\n",
      "inserted another chunk..., took 0.718 second\n",
      "inserted another chunk..., took 0.772 second\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      2\u001b[0m     t_start \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m----> 3\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     df\u001b[38;5;241m.\u001b[39mtpep_pickup_datetime \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df\u001b[38;5;241m.\u001b[39mtpep_pickup_datetime)\n\u001b[1;32m      5\u001b[0m     df\u001b[38;5;241m.\u001b[39mtpep_dropoff_datetime \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df\u001b[38;5;241m.\u001b[39mtpep_dropoff_datetime)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1698\u001b[0m, in \u001b[0;36mTextFileReader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   1697\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1698\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1699\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   1700\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1810\u001b[0m, in \u001b[0;36mTextFileReader.get_chunk\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m   1809\u001b[0m     size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnrows \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow)\n\u001b[0;32m-> 1810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1771\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m     (\n\u001b[1;32m   1775\u001b[0m         index,\n\u001b[1;32m   1776\u001b[0m         columns,\n\u001b[1;32m   1777\u001b[0m         col_dict,\n\u001b[0;32m-> 1778\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1779\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1780\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 230\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    232\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:833\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    t_start = time()\n",
    "    df = next(df_iter)\n",
    "    df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "    df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "    \n",
    "    df.to_sql(name='yellow_taxi_data', con=engine,if_exists='append')\n",
    "    t_end = time()\n",
    "    print(\"inserted another chunk..., took %.3f second\" % (t_end - t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f703b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-22 15:41:31--  http://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.228.56, 52.217.33.94, 52.216.138.85, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.228.56|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12322 (12K) [application/octet-stream]\n",
      "Saving to: ‘taxi+_zone_lookup.csv’\n",
      "\n",
      "taxi+_zone_lookup.c 100%[===================>]  12,03K  --.-KB/s    in 0,01s   \n",
      "\n",
      "2023-01-22 15:41:32 (851 KB/s) - ‘taxi+_zone_lookup.csv’ saved [12322/12322]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ab5251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = pd.read_csv('taxi+_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88b6e8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationID</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Zone</th>\n",
       "      <th>service_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LocationID        Borough                     Zone service_zone\n",
       "0           1            EWR           Newark Airport          EWR\n",
       "1           2         Queens              Jamaica Bay    Boro Zone\n",
       "2           3          Bronx  Allerton/Pelham Gardens    Boro Zone\n",
       "3           4      Manhattan            Alphabet City  Yellow Zone\n",
       "4           5  Staten Island            Arden Heights    Boro Zone"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cd5669a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zones.to_sql(name='zones', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7419e9a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
